# Flink 笔记

数据处理一般分为两类：事务型处理和分析型处理



## 事务型处理

企业在日常业务运营中会用到各种应用，这些应用系统通常都会设置独立的数据处理层和数据存储层。

## 分析型处理

存储于不同事务型数据库系统中的数据，可以为企业提供业务运营相关的分析见解。例如：通过分析订单处理系统中的数据来获知销售增长率。用于存储事务性数据的多个数据库系统通常都是相互隔离的，如果能将他们联合分析必然创造更高的价值。



对于分析类查询，通常不会直接在事务型数据库上执行，而是将数据复制到一个专门用来处理分析类查询的数据仓库。向数据仓库拷贝数据的过程被称为提取-转换-加载(Extract-Transform-Load,ETL)。ETL的基本流程是：从事务型数据库中提取数据，将其转换为通用表示形式，最终加载到分析型数据库中。



## 状态化流处理

任何一个处理事件流的应用，如果要支持跨多条记录的转换操作，都必须是有状态的，即能够存储和访问中间结果。有状态的流处理应用通常会从事件日志中读取事件记录。



## 事件驱动型应用

事件驱动型应用是一类通过接收事件流触发特定应用业务逻辑的有状态的流式应用。根据业务逻辑的不同，此类应用可支持触发报警或发送电子邮件之类的操作。典型的应用场景：实时推荐，模式识别或复杂事件处理，异常检测。





## 有状态的流处理

### 事件驱动型应用

从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。

### 数据分析型应用

流式查询或应用程序不是读取有限的数据集，而是接受实时事件流，不断生成和更新结果。结果要么写入外部数据库，要么作为内部状态进行维护。

### 数据管道型应用

在数据分析的应用中，通常会定期触发ETL任务，将数据从事务数据库系统复制到分析数据库或数据仓库



### Lambda架构

如果使用分布式架构获取更大的吞吐量，会带来一个问题，怎样保证数据处理的顺序是正确的。



## 实现数据并行

把一个算子“复制多份”到多个节点，数据来了之后就可以到其中任意一个执行，这样一来，一个算子任务就被拆分成了多个并行的子任务，再将它们分发到不同节点，就实现了真正的并行计算。一个特定算子的子任务的个数被称之为其并行度。包含并行子任务的数据流，就是并行数据，它需要多个分区来分配并行任务。一般情况下，一个流程序的并行度，可以认为就是其所有算子的最大的并行度。

### 算子间的数据传输

#### 一对一

数据流维护着分区以及元素的顺序。source和map算子，source算子读取数据之后，可以直接发送给map算子做处理，它们之间不需要重新分区，也不需要调整数据的顺序。这就意味着map算子的子任务，看到的元素个数和顺序跟source算子的子任务产生的完全一样.

### 重分区

数据流的分区会发生改变。每一个算子的子任务，会根据数据传输的策略，把数据发送到不同的下游目标任务，例如：keyby是分组操作，本质上居于键和哈希值进行了重分区，当并行度改变时，比如从并行度2的window算子，要传递到并行度为1的sink算子，这时的数据传输方式是平衡，会把数据均匀地向下游子任务分发出去。





## DataStream API

DataStream本身是flink中一个用来表示数据集合的类，我们编写的flink代码其实就是基于这种数据类型的处理。一个flink程序，其实就是对datastream的各种转换。具体来说，代码基本由以下部分构成：

- 获取执行环境（execution environment）
- 读取数据源（source）
- 定义基于数据的转换操作（transformations）
- 定义计算结果的输出位置（sink）
- 触发程序执行（execute）



### 执行环境

#### 创建执行环境

1. getExecutionEnvironment:他会根据当前运行的上下文直接得到正确的结果。如果程序是独立运行的，就返回一个本地执行环境：如果创建了jar包，然后从命令行调用它并提交到集群执行，那么就返回集群的执行环境。
2. createLocalEnvironment：返回一个本地执行环境
3. createRemoteEnvironment：这个方法返回集群执行环境。需要在调用时指定 JobManager 的主机名和端口号，并指定要在集群中运行的 Jar 包。

```java
StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment.createRemoteEnvironment("host", // JobManager 主机名1234, // JobManager 进程端口号"path/to/jarFile.jar" //  提交给 JobManager 的 JAR 包);
```



### 执行模式





### 源算子

想要处理数据，先得有数据，所以首要任务就是把数据读进来。Flink可以从各种来源获取数据，然后构建DataStream进行转换处理。一般将数据的输入来源称为数据源，而读取数据的算子就是源算子。

#### 从集合中读取数据

在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。一般用于测试。

### 从文件读取数据

一个比较常见的方式就是读取日志文件。

### 从socket读取数据

读取socket文本流

### 从kafka读取数据

与kafka的连接比较复杂，flink内部并没有提供预实现的方法。只能采用通用的addSource方式。







### 转换算子

#### map

主要用于将数据流中的数据进行转换，形成新的数据流。就是一个一一映射，消费一个元素就产出一个元素。

方法需要传入的参数是接口MapFunction的实现；返回值类型还是dataStream。



#### 过滤

对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则被过滤掉



#### 扁平映射

将数据流中的整体拆分成一个一个的个体使用。flatMap 操作会应用在每一个输入事件上面，FlatMapFunction 接口中定义了 flatMap 方法，用户可以重写这个方法，在这个方法中对输入数据进行处理，并决定是返回 0 个、1 个或多个结果数据。因此 flatMap 并没有直接定义返回值类型，而是通过一个“收集器”（Collector）来指定输出。希望输出结果时，只要调用收集器的.collect()方法就可以了；这个方法可以多次调用，也可以不调用。所以 flatMap 方法也可以实现 map 方法和 filter 方法的功能，当返回结果是 0 个的时候，就相当于对数据进行了过滤，当返回结果是 1 个的时候，相当于对数据进行了简单的转换操作。



### 聚和算子（Aggregation）

把所有数据聚在一起进行汇总合并

#### 按键分区(keyBy)

对海量数据做聚合需要进行分区并行处理。Keyby是聚合前必须要用到的一个算子。keyby通过指定键，可以将一条流从逻辑上划分成不同的分区，对应着任务槽task slot。基于不同的key，流中的数据将被分配到不同的分区中去，这样一来，所有具有相同key的数据，都将被发往同一个分区，那么下一步算子操作就将会在同一个slot中进行处理了。

keyBy()方法需要传入一个参数，这个参数指定了一个或一组 key。有很多不同的方法来指定 key：比如对于 Tuple 数据类型，可以指定字段的位置或者多个位置的组合；对于 POJO 类型，可以指定字段的名称（String）；另外，还可以传入 Lambda 表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取 key 的逻辑。

keyBy得到的结果将不再是DataStream，而是会将Datastream转换为KeyedStream。KeyedStream可以是认为是分区流或者键控流，他是对DataStream按照key的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定key的类型。



#### 简单聚合

有了按键分区的数据流 KeyedStream，我们就可以基于它进行聚合操作了。Flink 为我们内置实现了一些最基本、最简单的聚合 API，主要有以下几种：

- sum（）：在输入流上，对指定的字段做叠加求和的操作
- min（）：在输入流上，对指定的字段求最小值
- max（）：在输入流上，对指定的字段求最大值
- minBy（）：与 min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而 minBy()则会返回包含字段最小值的整条数据。
- maxBy（）：与 max()类似，在输入流上针对指定字段求最大值。两者区别与min()/minBy()完全一致。



